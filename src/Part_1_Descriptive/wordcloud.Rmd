---
title: "Wordclouds"
output: html_notebook
---

```{r}
rm(list=ls())
# necessary packages
if (!require("pacman")) install.packages("pacman") ; require("pacman")
p_load(rtweet, httr,tidyverse)
p_load(tm,wordcloud, wordcloud2)
p_load(stringr)
p_load(tibble)
p_load(dplyr)
```

```{r}
load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/All_tweets_all_features.RData")
```

```{r}
# change to text
text <- all_tweets$text
text <- iconv(text,'latin1', 'ascii', sub = '')
```

```{r}
#creating corpus
myCorpus <- Corpus(VectorSource(text)) %>%
  tm_map(content_transformer(str_to_lower)) %>%
  tm_map(removePunctuation) %>%
  tm_map(removeNumbers) %>%
  tm_map(stripWhitespace)
myStopwords <- c(stopwords('english'))
myCorpus <- tm_map(myCorpus, removeWords, myStopwords)


tdm <- TermDocumentMatrix(myCorpus)
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- tibble(word = names(v),freq=v)

#filtering the tibble
d <- d %>% filter(word != "starbucks") %>% arrange(desc(freq))
d <- d[which(d$freq>30),]

# making the wordcloud
wordcloud <- wordcloud2(d)
wordcloud
```
