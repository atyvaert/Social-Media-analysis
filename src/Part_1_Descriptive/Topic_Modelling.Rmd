---
title: "latent Dirichlet allocation"
output: html_notebook
---
 Applying Latent Dirichlet allocation in order to find the most important topic groups in Netflix Tweets 


```{r}
if (!require("pacman")) install.packages("pacman") ; require("pacman")
p_load(tidyverse, topicdoc, topicmodels, tm, textcat, rlang, tidytext, ggmap)
p_load(tidyverse, rtweet, httpuv, stringr, qdap, httr, wordcloud2, tm, tidytext, wordcloud)

```
```{r}
tweets %>% glimpse() 
#only use the text from the tweets 
text <- tweets_data(tweets) %>% pull(text)

```



```{r}
#develop model on smaller data set 

set.seed(123)
sample <- sample(unique(text), 
                              round(length(unique(text))/10), 
                              replace = FALSE)
length(sample)
```
```{r}

```


```{r}
#applying pre processing to the smaller sample 
myCorpus <- Corpus(VectorSource(sample)) %>%
  tm_map(content_transformer(str_to_lower)) %>%
  tm_map(removePunctuation) %>%
  tm_map(removeNumbers) %>%
  tm_map(stripWhitespace) 
  
myStopwords <- c(stopwords('english'),"starbucks", "the", "and", "ðŸ“Œ")
myCorpus <- tm_map(myCorpus, removeWords, myStopwords)

```
```{r}
dtm1 <- DocumentTermMatrix(myCorpus)
inspect(dtm1)
    
```


```{r}
lda_basic <- LDA(dtm1, 
                 control = list(seed = 33), 
                 k = 5)
terms(lda_basic, 20)
```


```{r}
#chose sprasety 
final_dtm <- removeSparseTerms(dtm1, 0.95) 
final_dtm

```
```{r}
#remove rows which have only 0 elements: each should contain at least 1 non zero 
rowTotals <- apply(final_dtm , 1, sum) #Find the sum of words in each Document
dtm_new   <- final_dtm[rowTotals> 0, ]
dtm_new
```


```{r}
#not only calculate the UMass but also try to find different likelihood measures 
#AIC and BIC 
topics <- seq(2,10,1)
alpha <- seq(0.2,0.8,0.2)
beta <- seq(0.2,0.8,0.2)
grid <- expand.grid(topics, alpha, beta)
colnames(grid) <- c('topics', 'alpha', 'beta')
grid$UMass <- rep(-99999999999, nrow(grid))
grid$LL <- rep(-99999999999, nrow(grid))

#This takes a while ==> best to load fitted grid
for (i in 1:nrow(grid)){
  K <- grid[i,'topics']
  a <- grid[i,'alpha']
  b <- grid[i,'beta']
  lda <- LDA(dtm_new, control = list(alpha = a, estimate.beta = b), k = K)
  grid[i,'UMass'] <- mean(topic_coherence(lda, dtm_new, top_n_tokens = 30))
}


```
```{r}
```


```{r}

(optimal_settings <- grid %>% filter(UMass == max(UMass))) 
optimal_settings

```


```{r}
grid %>% 
  filter(alpha==0.4 & beta==0.8) %>% 
  ggplot(aes(x = topics, y = UMass)) + geom_line() 
```


```{r}
grid %>% 
  filter(alpha==0.2 & beta==0.2) %>% 
  ggplot(aes(x = topics, y = UMass)) + geom_line() 
```


```{r}
lda <- LDA(dtm_new, 
           control = list(alpha = optimal_settings$alpha, 
                          estimate.beta = optimal_settings$beta),
           k = 10)

terms(lda, 20)


```

```{r}
lda <- LDA(dtm_new, 
           control = list(alpha = optimal_settings$alpha, 
                          estimate.beta = optimal_settings$beta),
           k = 3)

terms(lda, 20)
```


```{r}
```


```{r}
```


```{r}
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

