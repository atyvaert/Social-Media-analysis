---
title: "Basetablecreation"
output: html_notebook
---


```{r}
### Basetable creation and splitting ###

set.seed(123)
rm(list = ls())
library(quantmod)

###### Read Data ######
load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/All_tweets_all_features.RData")
```

```{r}
# Financial data
load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/Financial_Data.RData")
```

```{r}
# Clean tweet data
all_tweets <- subset(all_tweets, select = -c(text, user_id))
names(all_tweets)[2] <- "sentiment_by_dictionary"

# Splitting in train and test set
test_dates <- sample(unique(all_tweets$date), length(unique(all_tweets$date))*0.2)
dates <- unique(all_tweets$date)
train_dates <- dates[!(dates %in% test_dates)]

tweets_test <- all_tweets[all_tweets$date %in% test_dates,]
tweets_train <- all_tweets[all_tweets$date %in% train_dates,]

# MinMaxScale sentiments
num.cols <- sapply(all_tweets, is.numeric)

# apply on training set
mean_train <- colMeans(tweets_train[, num.cols])
sd_train <- sapply(tweets_train[, num.cols], sd)
tweets_train[, num.cols] <- scale(tweets_train[, num.cols], center = mean_train, scale = sd_train)

# apply on test set
tweets_test[, num.cols] <- scale(tweets_test[, num.cols], center = mean_train, scale = sd_train)
```

```{r}
# aggregate
tweets_train_agg <- aggregate(cbind(sentiment_by_basic,sentiment_weighted_mixed,sentiment_avg_mean, tweets_train$sentiment_by_dictionary,Topic_1,Topic_2) ~ tweets_train$date, tweets_train, mean)

tweets_test_agg <- aggregate(cbind(sentiment_by_basic,sentiment_weighted_mixed,sentiment_avg_mean,sentiment_by_dictionary,Topic_1,Topic_2) ~ tweets_test$date, tweets_test, mean)

# change colnames
colnames(tweets_train_agg) <- colnames(tweets_train)
colnames(tweets_test_agg) <- colnames(tweets_test)
```

```{r}
# Making basetable
basetable_train <- merge(tweets_train_agg,financial_data,by="date")
basetable_test <- merge(tweets_test_agg,financial_data,by="date")
```

```{r}
plot(basetable_train$date, basetable_train$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Hour", main = "Sentiment")

legend("bottomleft", legend=c("Dictionary", "Avg_Mean", "Basic","Weighted_mixed"), col=c("red", "blue", "green", "orange"), lty=1, cex=0.8)

lines(basetable_train$date, basetable_train$sentiment_avg_mean, type = "o", col = "blue")

lines(basetable_train$date, basetable_train$sentiment_by_basic, type = "o", col = "green")

lines(basetable_train$date, basetable_train$sentiment_weighted_mixed, type = "o", col = "orange")
```

```{r}
# choosing a sentiment column
basetable_train <- subset(basetable_train, select = -c(sentiment_by_basic,sentiment_weighted_mixed,sentiment_avg_mean))

basetable_test <- subset(basetable_test, select = -c(sentiment_by_basic,sentiment_weighted_mixed,sentiment_avg_mean))
```

```{r}
# missing values
colMeans(is.na(basetable_train))
colMeans(is.na(basetable_test))

# Handle outliers
# handle_outlier_z <- function(col){
#   col_z <- scale(col)
#   ifelse(abs(col_z)>3,
#          sign(col_z)*3*attr(col_z,"scaled:scale") + attr(col_z,"scaled:center"), col)
# }
# basetable_train[, num.cols] <-  sapply(basetable_train[, num.cols], FUN = handle_outlier_z)
```


```{r}
save(basetable_train, file = "/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/basetable_train.RData")
save(basetable_test, file = "/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/basetable_test.RData")
```




