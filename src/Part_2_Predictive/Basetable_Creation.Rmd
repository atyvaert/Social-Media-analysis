---
title: "Basetablecreation"
output: html_notebook
---


```{r}
### Basetable creation and splitting ###

set.seed(420)
rm(list = ls())
library(quantmod)

###### Read Data ######
load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/All_tweets_with_sentiment.RData")

```

```{r}
# Clean financial data & add technical indicators
getSymbols("SBUX")

ema <-EMA(Cl(SBUX),n=20)
bb <-BBands(Cl(SBUX),s.d=2)
M <- momentum(Cl(SBUX), n=2)
ROC <- ROC(Cl(SBUX),n=2)
macd <- MACD(Cl(SBUX), nFast=12, nSlow=26,
             nSig=9, maType=SMA)
rsi = RSI(Cl(SBUX), n=14)

financial_data <- Reduce(function(...) merge(..., all=TRUE), list(SBUX, ema, bb,M,ROC,macd,rsi))

financial_data <- data.frame(date=index(financial_data), coredata(financial_data))

financial_data$Target = financial_data$SBUX.Close - financial_data$SBUX.Open

financial_data$Target <- sign(financial_data$Target)

financial_data$date <- financial_data$date - 1
```

```{r}
# Clean tweet data
all_tweets <- subset(all_tweets, select = -c(text, user_id))
names(all_tweets)[5] <- "sentiment_by_dictionary"

# Clean date
all_tweets$date <- strptime(as.character(all_tweets$date), "%m/%d/%Y")
all_tweets$date <- format(all_tweets$date, "%Y-%m-%d")
all_tweets$date <- as.Date(all_tweets$date)


# Splitting in train and test set
test_dates <- sample(unique(all_tweets$date), length(unique(all_tweets$date))*0.2)
dates <- unique(all_tweets$date)
train_dates <- dates[!(dates %in% test_dates)]

tweets_test <- all_tweets[all_tweets$date==test_dates,]
tweets_train <- all_tweets[all_tweets$date==train_dates,]


# MinMaxScale sentiments
num.cols <- sapply(all_tweets, is.numeric)

# apply on training set
mean_train <- colMeans(tweets_train[, num.cols])
sd_train <- sapply(tweets_train[, num.cols], sd)
tweets_train[, num.cols] <- scale(tweets_train[, num.cols], center = mean_train, scale = sd_train)

# apply on test set
tweets_test[, num.cols] <- scale(tweets_test[, num.cols], center = mean_train, scale = sd_train)

# Aggregate
tweets_train_agg <- aggregate(cbind(tweets_train$sentiment_by_basic, tweets_train$sentiment_weighted_mixed, tweets_train$sentiment_average_mean, tweets_train$sentiment_by_dictionary) ~ tweets_train$date, tweets_train, mean)

tweets_test_agg <- aggregate(cbind(tweets_test$sentiment_by_basic, tweets_test$sentiment_weighted_mixed, tweets_test$sentiment_average_mean, tweets_test$sentiment_by_dictionary) ~ tweets_test$date, tweets_test, mean)

# Change colnames
colnames(tweets_train_agg) <- colnames(all_tweets)
colnames(tweets_test_agg) <- colnames(all_tweets)
```

```{r}
# Making basetable
basetable_train <- merge(tweets_train_agg,financial_data,by="date")
basetable_test <- merge(tweets_test_agg,financial_data,by="date")
```

```{r}
# Splitting in train and test set
train_x <- subset(basetable_train, select = -c(Target))
train_y <- basetable_train$Target

test_x <- subset(basetable_test, select = -c(Target))
test_y <- basetable_test$Target
```

```{r}
# Detect missing values
colMeans(is.na(basetable_train))
colMeans(is.na(basetable_test))

# Handle outliers
handle_outlier_z <- function(col){
  col_z <- scale(col)
  ifelse(abs(col_z)>3,
         sign(col_z)*3*attr(col_z,"scaled:scale") + attr(col_z,"scaled:center"), col)
}

num.cols <- sapply(basetable_train, is.numeric)
basetable_train[, num.cols] <-  sapply(basetable_train[, num.cols], FUN = handle_outlier_z)
```


```{r}
save(basetable_train, file = "/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/basetable_train.RData")
save(basetable_test, file = "/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/basetable_test.RData")
```




