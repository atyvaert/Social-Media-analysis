---
title: "R Notebook"
output: html_notebook
---

```{r}
set.seed(123)
rm(list = ls())

library(pROC)
library(ROSE)
library(MASS)
library(magrittr)
library(pROC)
library(lightgbm)



load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/basetable_train.RData")

load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/basetable_test.RData")
```

```{r}
#delete date column
basetable_train <- subset(basetable_train, select = -date)
basetable_test <- subset(basetable_test, select = -date)

#make variables
train_x <- subset(basetable_train, select = -Target)
train_y <- basetable_train$Target

test_x <- subset(basetable_test, select = -Target)
test_y <- basetable_test$Target

dtrain <- lgb.Dataset(data = as.matrix(train_x), label = train_y)
test_matrix_x<-as.matrix(test_x)
```

```{r}
# Determining the hyperparameters
lgb.grid<-list(objective="binary",
                num_leaves=8,
                max_depth=14,
                metric="auc",
                boosting="gbdt",
                learning_rate=0.005,
                num_iterations=5000,
                min_data_in_leaf=40)
```

```{r}
# Modeling
lgb.model <- lgb.train(data = dtrain,params = lgb.grid)
preds<-predict(lgb.model,test_matrix_x)

#rounding the values
preds[preds >= 0.5] <- 1
preds[preds < 0.5] <- -1

auc <- pROC::auc(test_y,preds)

#confusion matrix
cm = as.matrix(table(Actual = test_y, Predicted = preds))
n = sum(cm) # number of instances
nc = nrow(cm) # number of classes
diag = diag(cm) # number of correctly classified instances per class 
rowsums = apply(cm, 1, sum) # number of instances per class
colsums = apply(cm, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted classes

#accuracy (fraction of instances that is correctly classified)
accuracy = sum(diag) / n
```

```{r}
#look at importance features
feature_importance <- varImp(lgb.model, scale = FALSE)
```


