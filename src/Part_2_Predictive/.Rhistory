tweets_train_agg <- aggregate(cbind( tweets_train$sentiment_by_dictionary,Topic_1,Topic_2) ~ tweets_train$date, tweets_train, mean)
tweets_test_agg <- aggregate(cbind(sentiment_by_dictionary,Topic_1,Topic_2) ~ tweets_test$date, tweets_test, mean)
# change colnames
colnames(tweets_train_agg) <- colnames(tweets_train)
colnames(tweets_test_agg) <- colnames(tweets_test)
plot(tweets_test_agg$sentiment_by_dictionary)
plot(tweets_test_agg$sentiment_by_dictionary,tweets_test_agg$date)
plot(tweets_test_agg$date,tweets_test_agg$sentiment_by_dictionary)
plot(tweets_train_agg$date,tweets_train_agg$sentiment_by_dictionary)
abline(lm(tweets_train_agg$sentiment_by_dictionary ~ tweets_train_agg$date))
### Basetable creation and splitting ###
set.seed(123)
rm(list = ls())
library(quantmod)
###### Read Data ######
load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/All_tweets_all_features.RData")
# Financial data
load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/Financial_Data.RData")
# Clean tweet data
all_tweets <- subset(all_tweets, select = -c(text, user_id))
names(all_tweets)[2] <- "sentiment_by_dictionary"
# Splitting in train and test set
test_dates <- sample(unique(all_tweets$date), length(unique(all_tweets$date))*0.2)
dates <- unique(all_tweets$date)
train_dates <- dates[!(dates %in% test_dates)]
tweets_test <- all_tweets[all_tweets$date %in% test_dates,]
tweets_train <- all_tweets[all_tweets$date %in% train_dates,]
# MinMaxScale sentiments
num.cols <- sapply(all_tweets, is.numeric)
# apply on training set
mean_train <- colMeans(tweets_train[, num.cols])
sd_train <- sapply(tweets_train[, num.cols], sd)
tweets_train[, num.cols] <- scale(tweets_train[, num.cols], center = mean_train, scale = sd_train)
# apply on test set
tweets_test[, num.cols] <- scale(tweets_test[, num.cols], center = mean_train, scale = sd_train)
# choosing a sentiment column
tweets_train <- subset(tweets_train, select = -c(sentiment_by_basic,sentiment_weighted_mixed,sentiment_avg_mean))
tweets_test <- subset(tweets_test, select = -c(sentiment_by_basic,sentiment_weighted_mixed,sentiment_avg_mean))
# aggregate
tweets_train_agg <- aggregate(cbind( tweets_train$sentiment_by_dictionary,Topic_1,Topic_2) ~ tweets_train$date, tweets_train, mean)
tweets_test_agg <- aggregate(cbind(sentiment_by_dictionary,Topic_1,Topic_2) ~ tweets_test$date, tweets_test, mean)
# change colnames
colnames(tweets_train_agg) <- colnames(tweets_train)
colnames(tweets_test_agg) <- colnames(tweets_test)
plot(tweets_train_agg$date,tweets_train_agg$sentiment_by_dictionary)
abline(lm(tweets_train_agg$sentiment_by_dictionary ~ tweets_train_agg$date))
plot(tweets_train_agg$sentiment_by_dictionary,type = "o")
plot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Day", main = "Sentiment")
plot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary,type = "o", col = "black", xlab = "Date", ylab = "Average Sentiment per Day", main = "Sentiment")
### Basetable creation and splitting ###
set.seed(123)
rm(list = ls())
library(quantmod)
###### Read Data ######
load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/All_tweets_all_features.RData")
# Financial data
load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/Financial_Data.RData")
# Clean tweet data
all_tweets <- subset(all_tweets, select = -c(text, user_id))
names(all_tweets)[2] <- "sentiment_by_dictionary"
# Splitting in train and test set
test_dates <- sample(unique(all_tweets$date), length(unique(all_tweets$date))*0.2)
dates <- unique(all_tweets$date)
train_dates <- dates[!(dates %in% test_dates)]
tweets_test <- all_tweets[all_tweets$date %in% test_dates,]
tweets_train <- all_tweets[all_tweets$date %in% train_dates,]
# MinMaxScale sentiments
num.cols <- sapply(all_tweets, is.numeric)
# apply on training set
mean_train <- colMeans(tweets_train[, num.cols])
sd_train <- sapply(tweets_train[, num.cols], sd)
tweets_train[, num.cols] <- scale(tweets_train[, num.cols], center = mean_train, scale = sd_train)
# apply on test set
tweets_test[, num.cols] <- scale(tweets_test[, num.cols], center = mean_train, scale = sd_train)
# aggregate
tweets_train_agg <- aggregate(cbind(sentiment_by_basic,sentiment_weighted_mixed,sentiment_avg_mean, tweets_train$sentiment_by_dictionary,Topic_1,Topic_2) ~ tweets_train$date, tweets_train, mean)
tweets_test_agg <- aggregate(cbind(sentiment_by_basic,sentiment_weighted_mixed,sentiment_avg_mean,sentiment_by_dictionary,Topic_1,Topic_2) ~ tweets_test$date, tweets_test, mean)
View(tweets_train_agg)
View(tweets_test_agg)
# change colnames
colnames(tweets_train_agg) <- colnames(tweets_train)
colnames(tweets_test_agg) <- colnames(tweets_test)
lines(tweets_train_agg$sentiment_avg_mean, type = "o", col = "blue")
plot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Day", main = "Sentiment")
lines(tweets_train_agg$sentiment_avg_mean, type = "o", col = "blue")
lines(tweets_train_agg$sentiment_avg_mean, type = "o", col = "blue")
View(tweets_train_agg)
plot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Day", main = "Sentiment")
lines(tweets_train_agg$date, tweets_train_agg$sentiment_avg_mean, type = "o", col = "blue")
plot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Day", main = "Sentiment")
lines(tweets_train_agg$date, tweets_train_agg$sentiment_avg_mean, type = "o", col = "blue")
legend(1, 95, legend=c("Dictionary", "Avg_Mean"),
col=c("red", "blue"), lty=1:2, cex=0.8)
plot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Day", main = "Sentiment")
lines(tweets_train_agg$date, tweets_train_agg$sentiment_avg_mean, type = "o", col = "blue")
legend(1, 95, legend=c("Dictionary", "Avg_Mean"),
col=c("red", "blue"), lty=1:2, cex=0.8)
show()
plot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Day", main = "Sentiment")
lines(tweets_train_agg$date, tweets_train_agg$sentiment_avg_mean, type = "o", col = "blue")
legend(1, 95, legend=c("Dictionary", "Avg_Mean"),
col=c("red", "blue"), lty=1:2, cex=0.8)
plot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Day", main = "Sentiment")
legend(1, 95, legend=c("Dictionary", "Avg_Mean"),
col=c("red", "blue"), lty=1:2, cex=0.8)
lines(tweets_train_agg$date, tweets_train_agg$sentiment_avg_mean, type = "o", col = "blue")
legend(1, 95, legend=c("Dictionary", "Avg_Mean"),
col=c("red", "blue"), lty=1:2, cex=0.8)
plot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Day", main = "Sentiment")
legend(1, 95, legend=c("Dictionary", "Avg_Mean"),
col=c("red", "blue"), lty=1:2, cex=0.8)
plot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Day", main = "Sentiment")
legend(1, 95, legend=c("Dictionary", "Avg_Mean"),
col=c("red", "blue"), lty=1:2, cex=0.8)
legend(1, 95, legend=c("Dictionary", "Avg_Mean"),
col=c("red", "blue"), lty=1:2, cex=0.8)
library(ggplot2)
ggplot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Day", main = "Sentiment")
ggplot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary)
?ggplot
ggplot(tweets_train_agg$sentiment_by_dictionary)
ggplot(tweets_train_agg)
$sentiment_by_dictionary
ggplot(tweets_train_agg$sentiment_by_dictionary)
plot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Day", main = "Sentiment")
legend(1, 95, legend=c("Dictionary", "Avg_Mean"),
col=c("red", "blue"), lty=1:2, cex=0.8)
lines(tweets_train_agg$date, tweets_train_agg$sentiment_avg_mean, type = "o", col = "blue")
plot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Day", main = "Sentiment")
legend(1, 95, legend=c("Dictionary", "Avg_Mean"),
col=c("red", "blue"), lty=1:2, cex=0.8)
lines(tweets_train_agg$date, tweets_train_agg$sentiment_avg_mean, type = "o", col = "blue")
plot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Day", main = "Sentiment")
legend("bottomleft", legend=c("Dictionary", "Avg_Mean"),
col=c("red", "blue"), lty=1:2, cex=0.8)
lines(tweets_train_agg$date, tweets_train_agg$sentiment_avg_mean, type = "o", col = "blue")
plot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Day", main = "Sentiment")
legend("bottomleft", legend=c("Dictionary", "Avg_Mean"),
col=c("red", "blue"), lty=1:2, cex=0.8)
lines(tweets_train_agg$date, tweets_train_agg$sentiment_avg_mean, type = "o", col = "blue")
plot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Day", main = "Sentiment")
legend("bottomleft", legend=c("Dictionary", "Avg_Mean"),
col=c("red", "blue"))
lines(tweets_train_agg$date, tweets_train_agg$sentiment_avg_mean, type = "o", col = "blue")
plot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Day", main = "Sentiment")
legend("bottomleft", legend=c("Dictionary", "Avg_Mean"),
col=c("red", "blue"), lty=1:2)
lines(tweets_train_agg$date, tweets_train_agg$sentiment_avg_mean, type = "o", col = "blue")
plot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Day", main = "Sentiment")
legend("bottomleft", legend=c("Dictionary", "Avg_Mean"),
col=c("red", "blue"), lty=1:2, cex=0.8)
lines(tweets_train_agg$date, tweets_train_agg$sentiment_avg_mean, type = "o", col = "blue")
plot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Day", main = "Sentiment")
legend("bottomleft", legend=c("Dictionary", "Avg_Mean"),
col=c("red", "blue"), cex=0.8)
lines(tweets_train_agg$date, tweets_train_agg$sentiment_avg_mean, type = "o", col = "blue")
plot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Day", main = "Sentiment")
legend("bottomleft", legend=c("Dictionary", "Avg_Mean"),
col=c("red", "blue"), lty=2, cex=0.8)
lines(tweets_train_agg$date, tweets_train_agg$sentiment_avg_mean, type = "o", col = "blue")
plot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Day", main = "Sentiment")
legend("bottomleft", legend=c("Dictionary", "Avg_Mean"),
col=c("red", "blue"), lty=1, cex=0.8)
lines(tweets_train_agg$date, tweets_train_agg$sentiment_avg_mean, type = "o", col = "blue")
plot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Hour", main = "Sentiment")
legend("bottomleft", legend=c("Dictionary", "Avg_Mean"),
col=c("red", "blue"), lty=1, cex=0.8)
lines(tweets_train_agg$date, tweets_train_agg$sentiment_avg_mean, type = "o", col = "blue")
legend("bottomleft", legend=c("Dictionary", "Avg_Mean", "Basic","Weighted_mixed"), col=c("red", "blue", "green", "orange"), lty=1, cex=0.8)
plot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Hour", main = "Sentiment")
legend("bottomleft", legend=c("Dictionary", "Avg_Mean", "Basic","Weighted_mixed"), col=c("red", "blue", "green", "orange"), lty=1, cex=0.8)
lines(tweets_train_agg$date, tweets_train_agg$sentiment_avg_mean, type = "o", col = "blue")
lines(tweets_train_agg$date, tweets_train_agg$sentiment_by_basic, type = "o", col = "green")
lines(tweets_train_agg$date, tweets_train_agg$sentiment_weighted_mixed, type = "o", col = "orange")
set.seed(123)
rm(list = ls())
library(pROC)
library(ROSE)
library(MASS)
library(magrittr)
library(pROC)
library(lightgbm)
load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/basetable_train.RData")
load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/basetable_test.RData")
#accuracy (fraction of instances that is correctly classified)
accuracy = sum(diag) / n
set.seed(123)
rm(list = ls())
library(pROC)
library(ROSE)
library(MASS)
library(magrittr)
library(pROC)
library(lightgbm)
load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/basetable_train.RData")
load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/basetable_test.RData")
train_x <- basetable_train[,-ncol(basetable_train)]
train_y <- basetable_train$Target
test_x <- basetable_test[,-ncol(basetable_test)]
test_y <- basetable_test$Target
dtrain <- lgb.Dataset(data = as.matrix(train_x), label = train_y)
test_matrix_x<-as.matrix(test_x)
# Determining the hyperparameters
lgb.grid<-list(objective="binary",
num_leaves=8,
max_depth=14,
metric="auc",
boosting="gbdt",
learning_rate=0.005,
num_iterations=5000,
min_data_in_leaf=40)
# Modeling
lgb.model <- lgb.train(data = dtrain,params = lgb.grid, )
preds<-predict(lgb.model,test_matrix_x)
#rounding the values
preds[preds >= 0.5] <- 1
preds[preds < 0.5] <- -1
#confusion matrix
cm = as.matrix(table(Actual = test_y, Predicted = preds))
n = sum(cm) # number of instances
nc = nrow(cm) # number of classes
diag = diag(cm) # number of correctly classified instances per class
rowsums = apply(cm, 1, sum) # number of instances per class
colsums = apply(cm, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted classes
#accuracy (fraction of instances that is correctly classified)
accuracy = sum(diag) / n
accuracy
set.seed(123)
rm(list = ls())
load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/basetable_train.RData")
load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/basetable_test.RData")
#make variables
train_x <- basetable_train[,-ncol(basetable_train)]
train_y <- basetable_train$Target
test_x <- basetable_test[,-ncol(basetable_test)]
test_y <- basetable_test$Target
#build model
model_binomial <-  glm(train_y ~ ., data = basetable_train, family = "binomial")
test_y <- ifelse(test_y < 0, 0, 1)
test_y <- basetable_test$Target
test_y <- ifelse(test_y < 0, 0, 1)
train_y <- ifelse(train_y < 0, 0, 1)
#build model
model_binomial <-  glm(train_y ~ ., data = basetable_train, family = "binomial")
model_proportions <- predict(model_binomial, newdata = basetable_test, type = "response")
#build model
model_binomial <-  glm(train_y ~ ., data = train_x, family = "binomial")
model_proportions <- predict(model_binomial, newdata = basetable_test, type = "response")
#build model
model_binomial <-  glm(train_y ~ ., data = train_x, family = "binomial")
model_proportions <- predict(model_binomial, newdata = test_x, type = "response")
### Basetable creation and splitting ###
set.seed(123)
rm(list = ls())
library(quantmod)
###### Read Data ######
load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/All_tweets_all_features.RData")
# Financial data
load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/Financial_Data.RData")
# Clean tweet data
all_tweets <- subset(all_tweets, select = -c(text, user_id))
names(all_tweets)[2] <- "sentiment_by_dictionary"
# Splitting in train and test set
test_dates <- sample(unique(all_tweets$date), length(unique(all_tweets$date))*0.2)
dates <- unique(all_tweets$date)
train_dates <- dates[!(dates %in% test_dates)]
tweets_test <- all_tweets[all_tweets$date %in% test_dates,]
tweets_train <- all_tweets[all_tweets$date %in% train_dates,]
# MinMaxScale sentiments
num.cols <- sapply(all_tweets, is.numeric)
# apply on training set
mean_train <- colMeans(tweets_train[, num.cols])
sd_train <- sapply(tweets_train[, num.cols], sd)
tweets_train[, num.cols] <- as.numeric(scale(tweets_train[, num.cols], center = mean_train, scale = sd_train))
# apply on test set
tweets_test[, num.cols] <- as.numeric(scale(tweets_test[, num.cols], center = mean_train, scale = sd_train))
# aggregate
tweets_train_agg <- aggregate(cbind(sentiment_by_basic,sentiment_weighted_mixed,sentiment_avg_mean, tweets_train$sentiment_by_dictionary,Topic_1,Topic_2) ~ tweets_train$date, tweets_train, mean)
tweets_test_agg <- aggregate(cbind(sentiment_by_basic,sentiment_weighted_mixed,sentiment_avg_mean,sentiment_by_dictionary,Topic_1,Topic_2) ~ tweets_test$date, tweets_test, mean)
# change colnames
colnames(tweets_train_agg) <- colnames(tweets_train)
colnames(tweets_test_agg) <- colnames(tweets_test)
# choosing a sentiment column
tweets_train <- subset(tweets_train, select = -c(sentiment_by_basic,sentiment_weighted_mixed,sentiment_avg_mean))
tweets_test <- subset(tweets_test, select = -c(sentiment_by_basic,sentiment_weighted_mixed,sentiment_avg_mean))
plot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Hour", main = "Sentiment")
legend("bottomleft", legend=c("Dictionary", "Avg_Mean", "Basic","Weighted_mixed"), col=c("red", "blue", "green", "orange"), lty=1, cex=0.8)
lines(tweets_train_agg$date, tweets_train_agg$sentiment_avg_mean, type = "o", col = "blue")
lines(tweets_train_agg$date, tweets_train_agg$sentiment_by_basic, type = "o", col = "green")
lines(tweets_train_agg$date, tweets_train_agg$sentiment_weighted_mixed, type = "o", col = "orange")
# Making basetable
basetable_train <- merge(tweets_train_agg,financial_data,by="date")
basetable_test <- merge(tweets_test_agg,financial_data,by="date")
# Splitting in train and test set
train_x <- subset(basetable_train, select = -c(Target))
train_y <- basetable_train$Target
test_x <- subset(basetable_test, select = -c(Target))
test_y <- basetable_test$Target
# Detect missing values
colMeans(is.na(basetable_train))
colMeans(is.na(basetable_test))
# Handle outliers
handle_outlier_z <- function(col){
col_z <- scale(col)
ifelse(abs(col_z)>3,
sign(col_z)*3*attr(col_z,"scaled:scale") + attr(col_z,"scaled:center"), col)
}
num.cols <- sapply(basetable_train, is.numeric)
basetable_train[, num.cols] <-  sapply(basetable_train[, num.cols], FUN = handle_outlier_z)
save(basetable_train, file = "/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/basetable_train.RData")
save(basetable_test, file = "/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/basetable_test.RData")
set.seed(123)
rm(list = ls())
load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/basetable_train.RData")
load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/basetable_test.RData")
#make variables
train_x <- basetable_train[,-ncol(basetable_train)]
train_y <- basetable_train$Target
test_x <- basetable_test[,-ncol(basetable_test)]
test_y <- basetable_test$Target
test_y <- ifelse(test_y < 0, 0, 1)
train_y <- ifelse(train_y < 0, 0, 1)
#build model
model_binomial <-  glm(train_y ~ ., data = train_x, family = "binomial")
model_proportions <- predict(model_binomial, newdata = test_x, type = "response")
#build model
model_binomial <-  glm(train_y ~ ., data = basetable_train, family = "binomial")
model_proportions <- predict(model_binomial, newdata = basetable_test, type = "response")
### Basetable creation and splitting ###
set.seed(123)
rm(list = ls())
library(quantmod)
###### Read Data ######
load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/All_tweets_all_features.RData")
# Financial data
load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/Financial_Data.RData")
# Clean tweet data
all_tweets <- subset(all_tweets, select = -c(text, user_id))
names(all_tweets)[2] <- "sentiment_by_dictionary"
# Splitting in train and test set
test_dates <- sample(unique(all_tweets$date), length(unique(all_tweets$date))*0.2)
dates <- unique(all_tweets$date)
train_dates <- dates[!(dates %in% test_dates)]
tweets_test <- all_tweets[all_tweets$date %in% test_dates,]
tweets_train <- all_tweets[all_tweets$date %in% train_dates,]
# MinMaxScale sentiments
num.cols <- sapply(all_tweets, is.numeric)
# apply on training set
mean_train <- colMeans(tweets_train[, num.cols])
sd_train <- sapply(tweets_train[, num.cols], sd)
tweets_train[, num.cols] <- scale(tweets_train[, num.cols], center = mean_train, scale = sd_train)
# apply on test set
tweets_test[, num.cols] <- scale(tweets_test[, num.cols], center = mean_train, scale = sd_train)
# aggregate
tweets_train_agg <- aggregate(cbind(sentiment_by_basic,sentiment_weighted_mixed,sentiment_avg_mean, tweets_train$sentiment_by_dictionary,Topic_1,Topic_2) ~ tweets_train$date, tweets_train, mean)
tweets_test_agg <- aggregate(cbind(sentiment_by_basic,sentiment_weighted_mixed,sentiment_avg_mean,sentiment_by_dictionary,Topic_1,Topic_2) ~ tweets_test$date, tweets_test, mean)
# change colnames
colnames(tweets_train_agg) <- colnames(tweets_train)
colnames(tweets_test_agg) <- colnames(tweets_test)
# choosing a sentiment column
tweets_train <- subset(tweets_train, select = -c(sentiment_by_basic,sentiment_weighted_mixed,sentiment_avg_mean))
tweets_test <- subset(tweets_test, select = -c(sentiment_by_basic,sentiment_weighted_mixed,sentiment_avg_mean))
plot(tweets_train_agg$date, tweets_train_agg$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Hour", main = "Sentiment")
legend("bottomleft", legend=c("Dictionary", "Avg_Mean", "Basic","Weighted_mixed"), col=c("red", "blue", "green", "orange"), lty=1, cex=0.8)
lines(tweets_train_agg$date, tweets_train_agg$sentiment_avg_mean, type = "o", col = "blue")
lines(tweets_train_agg$date, tweets_train_agg$sentiment_by_basic, type = "o", col = "green")
lines(tweets_train_agg$date, tweets_train_agg$sentiment_weighted_mixed, type = "o", col = "orange")
# Making basetable
basetable_train <- merge(tweets_train_agg,financial_data,by="date")
basetable_test <- merge(tweets_test_agg,financial_data,by="date")
# Splitting in train and test set
train_x <- subset(basetable_train, select = -c(Target))
train_y <- basetable_train$Target
test_x <- subset(basetable_test, select = -c(Target))
test_y <- basetable_test$Target
num.cols <- sapply(basetable_train, is.numeric)
# Detect missing values
basetable_train[, num.cols] <- lapply(train_X_impute[, num.cols],
FUN = impute,
method = mean)
### Basetable creation and splitting ###
set.seed(123)
rm(list = ls())
library(quantmod)
###### Read Data ######
load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/All_tweets_all_features.RData")
#necessary functions
impute <- function(x, method = mean, val = NULL) {
if (is.null(val)) {
val <- method(x, na.rm = TRUE)
}
x[is.na(x)] <- val
return(x)
}
# Financial data
load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/Financial_Data.RData")
# Clean tweet data
all_tweets <- subset(all_tweets, select = -c(text, user_id))
names(all_tweets)[2] <- "sentiment_by_dictionary"
# Splitting in train and test set
test_dates <- sample(unique(all_tweets$date), length(unique(all_tweets$date))*0.2)
dates <- unique(all_tweets$date)
train_dates <- dates[!(dates %in% test_dates)]
tweets_test <- all_tweets[all_tweets$date %in% test_dates,]
tweets_train <- all_tweets[all_tweets$date %in% train_dates,]
# MinMaxScale sentiments
num.cols <- sapply(all_tweets, is.numeric)
# apply on training set
mean_train <- colMeans(tweets_train[, num.cols])
sd_train <- sapply(tweets_train[, num.cols], sd)
tweets_train[, num.cols] <- scale(tweets_train[, num.cols], center = mean_train, scale = sd_train)
# apply on test set
tweets_test[, num.cols] <- scale(tweets_test[, num.cols], center = mean_train, scale = sd_train)
# aggregate
tweets_train_agg <- aggregate(cbind(sentiment_by_basic,sentiment_weighted_mixed,sentiment_avg_mean, tweets_train$sentiment_by_dictionary,Topic_1,Topic_2) ~ tweets_train$date, tweets_train, mean)
tweets_test_agg <- aggregate(cbind(sentiment_by_basic,sentiment_weighted_mixed,sentiment_avg_mean,sentiment_by_dictionary,Topic_1,Topic_2) ~ tweets_test$date, tweets_test, mean)
# change colnames
colnames(tweets_train_agg) <- colnames(tweets_train)
colnames(tweets_test_agg) <- colnames(tweets_test)
# choosing a sentiment column
tweets_train <- subset(tweets_train, select = -c(sentiment_by_basic,sentiment_weighted_mixed,sentiment_avg_mean))
tweets_test <- subset(tweets_test, select = -c(sentiment_by_basic,sentiment_weighted_mixed,sentiment_avg_mean))
# Splitting in train and test set
train_x <- subset(basetable_train, select = -c(Target))
# Making basetable
basetable_train <- merge(tweets_train_agg,financial_data,by="date")
basetable_test <- merge(tweets_test_agg,financial_data,by="date")
# Splitting in train and test set
train_x <- subset(basetable_train, select = -c(Target))
train_y <- basetable_train$Target
test_x <- subset(basetable_test, select = -c(Target))
test_y <- basetable_test$Target
num.cols <- sapply(basetable_train, is.numeric)
# Detect missing values
basetable_train[, num.cols] <- lapply(train_X_impute[, num.cols],
FUN = impute,
method = mean)
num.cols <- sapply(basetable_train, is.numeric)
# Detect missing values
basetable_train[, num.cols] <- lapply(basetable_train[, num.cols],
FUN = impute,
method = mean)
basetable_test[, num.cols] <- mapply(basetable_test[, num.cols],
FUN = impute,
val = colMeans(train_X[, num.cols], na.rm = T))
num.cols <- sapply(basetable_train, is.numeric)
# Detect missing values
basetable_train[, num.cols] <- lapply(basetable_train[, num.cols],
FUN = impute,
method = mean)
basetable_test[, num.cols] <- mapply(basetable_test[, num.cols],
FUN = impute,
val = colMeans(basetable_train[, num.cols], na.rm = T))
colMeans(is.na(basetable_train))
colMeans(is.na(basetable_test))
# Handle outliers
handle_outlier_z <- function(col){
col_z <- scale(col)
ifelse(abs(col_z)>3,
sign(col_z)*3*attr(col_z,"scaled:scale") + attr(col_z,"scaled:center"), col)
}
basetable_train[, num.cols] <-  sapply(basetable_train[, num.cols], FUN = handle_outlier_z)
View(basetable_train)
### Basetable creation and splitting ###
set.seed(123)
rm(list = ls())
library(quantmod)
###### Read Data ######
load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/All_tweets_all_features.RData")
#necessary functions
impute <- function(x, method = mean, val = NULL) {
if (is.null(val)) {
val <- method(x, na.rm = TRUE)
}
x[is.na(x)] <- val
return(x)
}
# Financial data
load("/Users/wouterdewitte/Documents/GitHub/SMWA_Performance/data/Financial_Data.RData")
# Clean tweet data
all_tweets <- subset(all_tweets, select = -c(text, user_id))
names(all_tweets)[2] <- "sentiment_by_dictionary"
# Splitting in train and test set
test_dates <- sample(unique(all_tweets$date), length(unique(all_tweets$date))*0.2)
dates <- unique(all_tweets$date)
train_dates <- dates[!(dates %in% test_dates)]
tweets_test <- all_tweets[all_tweets$date %in% test_dates,]
tweets_train <- all_tweets[all_tweets$date %in% train_dates,]
# MinMaxScale sentiments
num.cols <- sapply(all_tweets, is.numeric)
# apply on training set
mean_train <- colMeans(tweets_train[, num.cols])
sd_train <- sapply(tweets_train[, num.cols], sd)
tweets_train[, num.cols] <- scale(tweets_train[, num.cols], center = mean_train, scale = sd_train)
# apply on test set
tweets_test[, num.cols] <- scale(tweets_test[, num.cols], center = mean_train, scale = sd_train)
# aggregate
tweets_train_agg <- aggregate(cbind(sentiment_by_basic,sentiment_weighted_mixed,sentiment_avg_mean, tweets_train$sentiment_by_dictionary,Topic_1,Topic_2) ~ tweets_train$date, tweets_train, mean)
tweets_test_agg <- aggregate(cbind(sentiment_by_basic,sentiment_weighted_mixed,sentiment_avg_mean,sentiment_by_dictionary,Topic_1,Topic_2) ~ tweets_test$date, tweets_test, mean)
# change colnames
colnames(tweets_train_agg) <- colnames(tweets_train)
colnames(tweets_test_agg) <- colnames(tweets_test)
# Making basetable
basetable_train <- merge(tweets_train_agg,financial_data,by="date")
basetable_test <- merge(tweets_test_agg,financial_data,by="date")
plot(basetable_train$date, basetable_train$sentiment_by_dictionary,type = "o", col = "red", xlab = "Date", ylab = "Average Sentiment per Hour", main = "Sentiment")
legend("bottomleft", legend=c("Dictionary", "Avg_Mean", "Basic","Weighted_mixed"), col=c("red", "blue", "green", "orange"), lty=1, cex=0.8)
lines(basetable_train$date, basetable_train$sentiment_avg_mean, type = "o", col = "blue")
lines(basetable_train$date, basetable_train$sentiment_by_basic, type = "o", col = "green")
lines(basetable_train$date, basetable_train$sentiment_weighted_mixed, type = "o", col = "orange")
